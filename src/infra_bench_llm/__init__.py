"""
infra_bench_llm: Benchmarking library for LLM inference on CPU-only infrastructure using Ollama.
"""
